# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


# The configuration file needs to define the sources, 
# the channels and the sinks.
# Sources, channels and sinks are defined per agent, 
# in this case called 'agent'

#agent.sources = spooldirSource, dirTailSource
agent.sources = dirTailSource
agent.channels = memoryChannel1 memoryChannel2
agent.sinks = myHDFSSink CEPSink

# Sources
agent.sources.spooldirSource.type = spooldir
agent.sources.spooldirSource.spoolDir = /tmp/spoolDir
agent.sources.spooldirSource.fileHeader = true
agent.sources.spooldirSource.interceptors = i1 i2
agent.sources.spooldirSource.interceptors.i1.type = org.apache.flume.interceptor.TimestampInterceptor$Builder
agent.sources.spooldirSource.interceptors.i2.type = org.apache.flume.interceptor.HostInterceptor$Builder
agent.sources.spooldirSource.interceptors.i2.preserveExisting = false
agent.sources.spooldirSource.interceptors.i2.hostHeader = hostname
agent.sources.spooldirSource.selector.type = replicating
agent.sources.spooldirSource.channels = memoryChannel1 memoryChannel2

# Tail Dir Source
agent.sources.dirTailSource.type = com.realtimecep.flume.sources.DirTailEventDrivenSource
agent.sources.dirTailSource.path = /Users/ted/hadoop/data/hdfs/logs
agent.sources.dirTailSource.filePrefix = hadoop
agent.sources.dirTailSource.scanPeriod = 3000
agent.sources.dirTailSource.debugThroughput = false
agent.sources.dirTailSource.interceptors = i1 i2
agent.sources.dirTailSource.interceptors.i1.type = org.apache.flume.interceptor.TimestampInterceptor$Builder
agent.sources.dirTailSource.interceptors.i2.type = org.apache.flume.interceptor.HostInterceptor$Builder
agent.sources.dirTailSource.interceptors.i2.preserveExisting = false
agent.sources.dirTailSource.interceptors.i2.hostHeader = hostname
agent.sources.dirTailSource.selector.type = replicating
agent.sources.dirTailSource.channels = memoryChannel1 memoryChannel2

# Channels
agent.channels.memoryChannel1.type = memory
agent.channels.memoryChannel1.capacity = 100
agent.channels.memoryChannel1.transactionCapacity = 10
agent.channels.memoryChannel1.keep-alive = 1

agent.channels.memoryChannel2.type = memory
agent.channels.memoryChannel2.capacity = 1000
agent.channels.memoryChannel2.transactionCapacity = 100
agent.channels.memoryChannel2.keep-alive = 1

# Sinks
agent.sinks.loggerSink.type = logger
agent.sinks.loggerSink.channel = memoryChannel1

agent.sinks.myHDFSSink.type = hdfs
agent.sinks.myHDFSSink.channel = memoryChannel2
agent.sinks.myHDFSSink.hdfs.path = hdfs://localhost:9000/data/%Y-%m-%d/%H
agent.sinks.myHDFSSink.hdfs.fileType = DataStream
agent.sinks.myHDFSSink.hdfs.writeFormat = Text
agent.sinks.myHDFSSink.hdfs.filePrefix = app
agent.sinks.myHDFSSink.hdfs.fileSuffix = .log
agent.sinks.myHDFSSink.hdfs.threadsPoolSize = 10
agent.sinks.myHDFSSink.hdfs.rollInterval = 60
agent.sinks.myHDFSSink.hdfs.rollSize = 125000
agent.sinks.myHDFSSink.hdfs.rollCount = 0
agent.sinks.myHDFSSink.hdfs.batchSize = 1000

agent.sinks.CEPSink.type = com.realtimecep.flume.sinks.CEPSink
agent.sinks.CEPSink.channel = memoryChannel1